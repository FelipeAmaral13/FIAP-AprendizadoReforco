{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento de Agente em Labirinto com Aprendizado por Reforço\n",
    "\n",
    "Neste código, um agente é treinado para navegar por um labirinto usando aprendizado por reforço. O labirinto é representado como uma grade e o agente pode executar quatro ações possíveis: \n",
    "* mover para cima, mover para baixo, mover para a esquerda e mover para a direita. \n",
    "\n",
    "O objetivo do agente é aprender a política ótima que o guia do estado inicial ao estado objetivo, maximizando a recompensa acumulada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurações iniciais\n",
    "\n",
    "Inicializar as configurações iniciais do ambiente do labirinto, como o tamanho do labirinto, o número de ações possíveis, a taxa de aprendizado, o fator de desconto e o número de episódios de treinamento. Além disso, inicializar uma matriz chamada q_table que será usada para armazenar os valores da função Q."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tamanho do labirinto\n",
    "GRID_SIZE = 10\n",
    "\n",
    "# Número de ações possíveis (cima, baixo, esquerda, direita)\n",
    "NUM_ACTIONS = 4\n",
    "\n",
    "# Taxa de aprendizado\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "# Fator de desconto\n",
    "DISCOUNT_FACTOR = 0.9\n",
    "\n",
    "# Número de episódios de treinamento\n",
    "NUM_EPISODES = 1000000\n",
    "\n",
    "# Inicialização da tabela-Q\n",
    "q_table = np.zeros((GRID_SIZE, GRID_SIZE, NUM_ACTIONS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição de funções \n",
    "\n",
    "Definir duas funções: \n",
    "\n",
    "* `choose_action`: que escolhe uma ação com base na estratégia epsilon-greedy.\n",
    "* `run_episode`: que executa um episódio de treinamento do agente no labirinto. \n",
    "\n",
    "A função choose_action decide se o agente deve explorar (escolhendo uma ação aleatória) ou explorar (escolhendo a ação com maior valor Q) com base no valor de epsilon. A função run_episode simula o movimento do agente no labirinto, atualiza a tabela Q com base na recompensa e na equação de Bellman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para escolher uma ação epsilon-greedy\n",
    "def choose_action(state, epsilon):\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        return random.randint(0, NUM_ACTIONS - 1)  # Escolhe uma ação aleatória\n",
    "    else:\n",
    "        return np.argmax(q_table[state[0], state[1]])\n",
    "\n",
    "# Função para executar um episódio\n",
    "def run_episode():\n",
    "    state = [0, 0]  # Estado inicial\n",
    "    goal = [0, GRID_SIZE - 1]  # Objetivo\n",
    "    epsilon = 0.1  # Valor de epsilon para exploração\n",
    "\n",
    "    while state != goal:\n",
    "        action = choose_action(state, epsilon)\n",
    "        new_state = state.copy()\n",
    "\n",
    "        # Simulação de movimento do agente\n",
    "        if action == 0:  # Mover para cima\n",
    "            new_state[0] = max(0, state[0] - 1)\n",
    "        elif action == 1:  # Mover para baixo\n",
    "            new_state[0] = min(GRID_SIZE - 1, state[0] + 1)\n",
    "        elif action == 2:  # Mover para a esquerda\n",
    "            new_state[1] = max(0, state[1] - 1)\n",
    "        elif action == 3:  # Mover para a direita\n",
    "            new_state[1] = min(GRID_SIZE - 1, state[1] + 1)\n",
    "\n",
    "        reward = -1  # Recompensa por movimento\n",
    "\n",
    "        # Atualização da tabela-Q usando a equação de Bellman\n",
    "        q_table[state[0], state[1], action] = (1 - LEARNING_RATE) * q_table[state[0], state[1], action] + LEARNING_RATE * (reward + DISCOUNT_FACTOR * np.max(q_table[new_state[0], new_state[1]]))\n",
    "\n",
    "        state = new_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do agente\n",
    "\n",
    "Esta célula treina o agente executando um número de episódios especificado por NUM_EPISODES. Cada episódio é executado chamando a função run_episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do agente\n",
    "for episode in range(NUM_EPISODES):\n",
    "    run_episode()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exibição da tabela-Q após o treinamento\n",
    "\n",
    "Esta célula exibe a tabela Q após o treinamento. A tabela Q contém os valores estimados para a função Q após o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela-Q após o treinamento:\n",
      "[[[-6.5132156  -6.86189404 -6.5132156  -6.12579511]\n",
      "  [-6.12579511 -6.5132156  -6.5132156  -5.6953279 ]\n",
      "  [-5.6953279  -6.12579511 -6.12579511 -5.217031  ]\n",
      "  [-5.217031   -5.6953279  -5.6953279  -4.68559   ]\n",
      "  [-4.68559    -5.217031   -5.217031   -4.0951    ]\n",
      "  [-4.0951     -4.68559    -4.68559    -3.439     ]\n",
      "  [-3.439      -4.0951     -4.0951     -2.71      ]\n",
      "  [-2.71       -3.439      -3.439      -1.9       ]\n",
      "  [-1.9        -2.71       -2.71       -1.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-6.5132156  -7.17570464 -6.86189404 -6.5132156 ]\n",
      "  [-6.12579511 -6.86189404 -6.86189404 -6.12579511]\n",
      "  [-5.6953279  -6.5132156  -6.5132156  -5.6953279 ]\n",
      "  [-5.217031   -6.12579511 -6.12579511 -5.217031  ]\n",
      "  [-4.68559    -5.6953279  -5.6953279  -4.68559   ]\n",
      "  [-4.0951     -5.217031   -5.217031   -4.0951    ]\n",
      "  [-3.439      -4.68559    -4.68559    -3.439     ]\n",
      "  [-2.71       -4.0951     -4.0951     -2.71      ]\n",
      "  [-1.9        -3.439      -3.439      -1.9       ]\n",
      "  [-1.         -2.62943371 -2.66249988 -1.89508691]]\n",
      "\n",
      " [[-6.86189404 -7.00013082 -7.07882458 -6.86189404]\n",
      "  [-6.5132156  -6.88673928 -7.11497695 -6.5132156 ]\n",
      "  [-6.12579511 -6.63716262 -6.77962704 -6.12579511]\n",
      "  [-5.6953279  -6.2986782  -6.48204366 -5.6953279 ]\n",
      "  [-5.217031   -5.925515   -6.02682882 -5.217031  ]\n",
      "  [-4.68559    -5.57114228 -5.68210353 -4.68559   ]\n",
      "  [-4.0951     -5.0712613  -5.14698413 -4.0951    ]\n",
      "  [-3.439      -4.61687617 -4.64698295 -3.439     ]\n",
      "  [-2.71       -4.02482568 -4.0309386  -2.71      ]\n",
      "  [-1.9        -2.85127873 -2.84907428 -2.52414443]]\n",
      "\n",
      " [[-6.78690971 -6.76576523 -6.79758783 -6.75694535]\n",
      "  [-6.64468787 -6.62448678 -6.67296586 -6.62563526]\n",
      "  [-6.37206701 -6.36976345 -6.38802784 -6.37030369]\n",
      "  [-6.03635875 -6.06348224 -6.11192427 -6.0374056 ]\n",
      "  [-5.64567164 -5.66370266 -5.70902874 -5.64784258]\n",
      "  [-5.19495868 -5.23947494 -5.28286803 -5.1935039 ]\n",
      "  [-4.67650621 -4.67556619 -4.7911553  -4.67607114]\n",
      "  [-4.09225097 -4.23540003 -4.21341752 -4.09218269]\n",
      "  [-3.43844531 -3.73527423 -3.69600634 -3.43844428]\n",
      "  [-2.70999993 -2.95829173 -3.05924209 -2.97020219]]\n",
      "\n",
      " [[-6.55024628 -6.53094673 -6.54293564 -6.54311039]\n",
      "  [-6.45260986 -6.40626921 -6.42205436 -6.42240721]\n",
      "  [-6.20696449 -6.23148414 -6.23050884 -6.21172736]\n",
      "  [-5.99283392 -5.96795807 -5.95473261 -5.9673588 ]\n",
      "  [-5.65703217 -5.68604484 -5.7010625  -5.66721679]\n",
      "  [-5.34173178 -5.37561717 -5.33304808 -5.34231258]\n",
      "  [-4.96368808 -5.02958765 -5.01029967 -4.96304219]\n",
      "  [-4.53583022 -4.56119551 -4.65206548 -4.54492526]\n",
      "  [-4.04683274 -4.09644934 -4.22356339 -4.03651735]\n",
      "  [-3.43848288 -3.47789714 -3.63227103 -3.61978435]]\n",
      "\n",
      " [[-6.32111947 -6.35362337 -6.35857552 -6.34649994]\n",
      "  [-6.23587839 -6.2421201  -6.26020339 -6.24975185]\n",
      "  [-6.09901194 -6.11914333 -6.100397   -6.0967307 ]\n",
      "  [-5.91713142 -5.91601302 -5.91291171 -5.91426354]\n",
      "  [-5.66473393 -5.69336269 -5.71553904 -5.66643629]\n",
      "  [-5.44676766 -5.447123   -5.40824921 -5.4110849 ]\n",
      "  [-5.12752486 -5.16003321 -5.15977852 -5.13669816]\n",
      "  [-4.8216753  -4.84088675 -4.81312176 -4.8342983 ]\n",
      "  [-4.49089622 -4.49694076 -4.52802455 -4.4898613 ]\n",
      "  [-4.07915244 -4.14375944 -4.24851856 -4.12024748]]\n",
      "\n",
      " [[-6.20719821 -6.1957681  -6.21056219 -6.19649283]\n",
      "  [-6.11389784 -6.1415351  -6.12804688 -6.13006128]\n",
      "  [-6.01219458 -6.01010844 -6.03122873 -6.01724852]\n",
      "  [-5.87936751 -5.86207535 -5.88016702 -5.83916986]\n",
      "  [-5.66631334 -5.67803764 -5.69472943 -5.66306759]\n",
      "  [-5.48511026 -5.49150508 -5.47648584 -5.46355149]\n",
      "  [-5.25269278 -5.3046329  -5.29924377 -5.25318151]\n",
      "  [-5.01322699 -5.06881681 -5.09229815 -5.01022672]\n",
      "  [-4.77224636 -4.82159081 -4.81386637 -4.78922859]\n",
      "  [-4.5799955  -4.58719447 -4.60493063 -4.58702397]]\n",
      "\n",
      " [[-6.09137372 -6.08852603 -6.06641401 -6.11983615]\n",
      "  [-6.04517388 -6.03734645 -6.07279056 -6.05477856]\n",
      "  [-5.93952673 -5.94465824 -5.96823036 -5.94739874]\n",
      "  [-5.81274517 -5.84241039 -5.81436919 -5.81759522]\n",
      "  [-5.6740844  -5.6710015  -5.69631912 -5.67972077]\n",
      "  [-5.51193651 -5.54580041 -5.5364066  -5.5110688 ]\n",
      "  [-5.35469886 -5.33136975 -5.37469142 -5.35916661]\n",
      "  [-5.17220502 -5.1604008  -5.20794996 -5.18490723]\n",
      "  [-4.99345143 -5.05199164 -5.02097404 -5.03319682]\n",
      "  [-4.88910976 -4.91498772 -4.91872143 -4.89324863]]\n",
      "\n",
      " [[-6.02473477 -6.0045884  -5.98392834 -6.02875818]\n",
      "  [-5.97751971 -5.97836948 -5.98112342 -5.97147342]\n",
      "  [-5.91313619 -5.91301789 -5.90088598 -5.87466434]\n",
      "  [-5.78435355 -5.81122392 -5.79733357 -5.80327076]\n",
      "  [-5.6983043  -5.67955146 -5.68994015 -5.67060046]\n",
      "  [-5.53566579 -5.53281356 -5.54845771 -5.54893633]\n",
      "  [-5.39843229 -5.36473993 -5.41379229 -5.35880659]\n",
      "  [-5.22958311 -5.24739336 -5.23811803 -5.21879497]\n",
      "  [-5.13207982 -5.1211684  -5.11453964 -5.14773403]\n",
      "  [-5.05572199 -5.02753749 -5.06820516 -5.04464051]]\n",
      "\n",
      " [[-5.97901734 -5.97490157 -5.97641643 -6.00445585]\n",
      "  [-5.93792461 -5.97145046 -5.96701958 -5.96973074]\n",
      "  [-5.88153899 -5.8611605  -5.89907031 -5.91865618]\n",
      "  [-5.80026777 -5.81969266 -5.81643158 -5.81889886]\n",
      "  [-5.7120779  -5.69828791 -5.70244916 -5.68168338]\n",
      "  [-5.54096674 -5.55867885 -5.57556964 -5.5373176 ]\n",
      "  [-5.38328449 -5.37138479 -5.40183751 -5.39498495]\n",
      "  [-5.28737032 -5.2869646  -5.25111428 -5.28832378]\n",
      "  [-5.19041147 -5.19005046 -5.19091438 -5.15318265]\n",
      "  [-5.09041424 -5.08916418 -5.11520707 -5.10049183]]]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar a tabela-Q após o treinamento\n",
    "print(\"Tabela-Q após o treinamento:\")\n",
    "print(q_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização da política aprendida\n",
    "\n",
    "a política aprendida pelo agente é visualizada. A política é obtida encontrando a ação com o maior valor Q para cada estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Política aprendida:\n",
      "[[3 3 3 3 3 3 3 3 3 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [3 1 1 0 0 3 1 3 3 0]\n",
      " [1 1 0 2 0 2 3 0 3 0]\n",
      " [0 0 3 2 0 2 0 2 3 0]\n",
      " [1 0 1 3 3 3 0 3 0 0]\n",
      " [2 1 0 0 1 3 1 1 0 0]\n",
      " [2 3 3 0 3 1 3 3 2 1]\n",
      " [1 0 1 0 3 3 1 2 3 1]]\n"
     ]
    }
   ],
   "source": [
    "# Visualização da política aprendida\n",
    "policy = np.argmax(q_table, axis=2)\n",
    "print(\"\\nPolítica aprendida:\")\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A política aprendida é uma representação das ações que o agente deve tomar em cada estado do labirinto para maximizar a recompensa esperada. Cada elemento da matriz representa um estado no labirinto e contém um valor que indica qual ação o agente deve escolher naquele estado. Os valores são mapeados da seguinte forma:\n",
    "\n",
    "- 0: Mover para cima\n",
    "- 1: Mover para baixo\n",
    "- 2: Mover para a esquerda\n",
    "- 3: Mover para a direita\n",
    "\n",
    "Portanto, a política aprendida mostra as ações recomendadas para cada posição no labirinto. Por exemplo, se você olhar para a célula [0, 0], que é o canto superior esquerdo, o valor 1 indica que o agente deve escolher a ação de \"Mover para baixo\" nesse estado. Da mesma forma, a célula [0, 1] tem um valor de 2, o que significa que o agente deve escolher a ação \"Mover para a esquerda\" no próximo estado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desenho do labirinto com setas vermelhas representando a política aprendida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Criar matriz de cores para as setas vermelhas\n",
    "arrow_color = np.zeros((GRID_SIZE, GRID_SIZE, 3), dtype=np.uint8)\n",
    "arrow_color[:, :, 2] = 255  # Define o canal vermelho como 255 (vermelho)\n",
    "\n",
    "# Desenhar o labirinto com as setas vermelhas\n",
    "cell_size = 100\n",
    "maze = np.zeros((GRID_SIZE * cell_size, GRID_SIZE * cell_size, 3), dtype=np.uint8)\n",
    "\n",
    "for i in range(GRID_SIZE):\n",
    "    for j in range(GRID_SIZE):\n",
    "        if policy[i, j] == 0:  # Cima\n",
    "            cv2.arrowedLine(maze, (j * cell_size + cell_size // 2, i * cell_size + cell_size // 2), (j * cell_size + cell_size // 2, i * cell_size + cell_size // 2 - 30), (0, 0, 255), 2)\n",
    "        elif policy[i, j] == 1:  # Baixo\n",
    "            cv2.arrowedLine(maze, (j * cell_size + cell_size // 2, i * cell_size + cell_size // 2), (j * cell_size + cell_size // 2, i * cell_size + cell_size // 2 + 30), (0, 0, 255), 2)\n",
    "        elif policy[i, j] == 2:  # Esquerda\n",
    "            cv2.arrowedLine(maze, (j * cell_size + cell_size // 2, i * cell_size + cell_size // 2), (j * cell_size + cell_size // 2 - 30, i * cell_size + cell_size // 2), (0, 0, 255), 2)\n",
    "        elif policy[i, j] == 3:  # Direita\n",
    "            cv2.arrowedLine(maze, (j * cell_size + cell_size // 2, i * cell_size + cell_size // 2), (j * cell_size + cell_size // 2 + 30, i * cell_size + cell_size // 2), (0, 0, 255), 2)\n",
    "\n",
    "plt.imshow(maze)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_AR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
